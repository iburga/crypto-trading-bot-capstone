FROM jupyter/scipy-notebook:latest

USER root

# Install Java (required by Spark)
RUN apt-get update && apt-get install -y openjdk-11-jdk curl

# Set Spark version (without specifying Hadoop variant)
ENV SPARK_VERSION=3.4.2

# Download Spark with default package (use prebuilt hadoop3 if needed)
RUN curl -fsSL https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop3.tgz | tar -xz -C /opt/ && \
    mv /opt/spark-${SPARK_VERSION}-bin-hadoop3 /opt/spark

ENV SPARK_HOME=/opt/spark
ENV PATH=$SPARK_HOME/bin:$PATH

# Switch back to Jupyter user
USER $NB_UID

